# Divya Vemula  
ğŸ“§ vemuladivya696@gmail.com | ğŸ“ +1 812-552-6230 | ğŸŒ [LinkedIn](https://www.linkedin.com/in/divyavemula96/) | ğŸ’» [GitHub](https://github.com/DivyaVemula95) | ğŸ“ Atlanta, GA

---

## ğŸ§  Profile Summary  
Versatile software engineer and data specialist with 5+ years of experience designing and deploying scalable machine learning systems and data solutions. Proven success in automating processes, building robust data pipelines, and generating actionable insights that improve business outcomes. Strong foundation in predictive analytics, natural language processing, and cloud-native deployments. Currently pursuing an MS in Computer Information Systems, specializing in AI/ML and big data engineering.

---

## ğŸ“ Education  
**Master of Science in Computer Information Systems**  
*Georgia State University â€“ J. Mack Robinson College of Business*  
ğŸ“ Atlanta, GA | Aug 2024 â€“ Aug 2025 | GPA: 3.88/4.0

**Bachelor of Engineering in Electronics & Communication Engineering**  
*Anna University*  
ğŸ“ Chennai, India | May 2013 â€“ Jun 2017 | GPA: 3.2/4.0

---

## ğŸ›  Core Skills  
- **Programming**: Python, SQL, R, C#, .NET, NoSQL, React.js  
- **Platforms**: GCP, AWS, Databricks, Kubernetes, Docker, Hadoop, HDFS, MongoDB  
- **Data & Cloud Tools**: Airflow, Power BI, Tableau, Power Automate, Google Colab, Jupyter  
- **ML & AI**: Regression, Classification, Clustering, CNN, RNN, LSTM, Transformers, RAG, BERT, GPT, AutoML  
- **NLP & LLMs**: spaCy, NLTK, Prompt Engineering, LangChain, Fine-tuning, Vector DBs  
- **Data Systems**: ETL/ELT, Data Lakes, Warehouses, Lakehouse, Graph DBs, Data Governance  
- **Libraries/Frameworks**: Scikit-learn, TensorFlow, PyTorch, Pandas, NumPy, SciPy, PySpark  
- **Other**: Data Storytelling, Model Monitoring (Evidently AI), CI/CD, Git, Jenkins, SPFx  

---

## ğŸ‘©â€ğŸ’» Professional Experience  

### **AI/ML Engineer**  
*Starr Insurance Companies â€“ Atlanta, GA*  
**Dec 2024 â€“ Jan 2026**  
- Architected Snowflake ELT pipelines using dbt, transforming raw policy, claims, and customer data into dimensional fact and dimension models, improving analytics and ML feature availability by 45%.  
- Engineered scalable AWS-based data ingestion pipelines (S3, RDS â†’ Snowflake), processing 1M+ insurance records daily with optimized performance and governed access.
- Deployed and operationalized machine learning models on AWS SageMaker, integrating Lambda-based event-driven inference to deliver real-time risk and decisioning outputs with <200 ms latency.   
- Orchestrated end-to-end data and ML workflows using Apache Airflow, reducing pipeline failures by 40% and ensuring SLA-compliant processing across ingestion, transformation, and scoring layers.
- Developed FastAPI/Flask services to expose ML and GenAI-driven insights to internal insurance applications, supporting 5+ downstream systems and improving decision turnaround time by 30%. 
- Implemented CI/CD pipelines with Docker and GitHub Actions, enabling automated testing, versioned deployments, and rollback strategies, reducing production release cycles by 50%.
- Designed interactive Power BI dashboards using DAX and Power Query to visualize underwriting KPIs, portfolio risk indicators, and model outputs, driving 25% faster executive decision-making.
- Partnered with underwriting, actuarial, and compliance teams to align data models, ML outputs, and dashboards with regulatory and audit requirements, ensuring enterprise-grade reliability.

### **Graduate Research Assistant â€“ AI/ML Research & Development**  
*Georgia State University â€“ Atlanta, GA*  
**Aug 2024 â€“ Aug 2025**  
- Designed and deployed an AI-powered resume screening platform using BERT and spaCy, reducing manual resume processing time by 85% and ensuring consistency in candidate evaluation.  
- Implemented robust quality checks for NLP pipelines and classification models, including drift detection and automated retraining triggers using Evidently AI.  
- Automated administrative workflows across departments with Power Automate, saving 20+ hours/week and reducing human error in daily operations.  
- Developed a hybrid skill extraction model combining TF-IDF and Word2Vec, increasing role-candidate match accuracy to 90%.  
- Orchestrated end-to-end cloud deployment on AWS (Lambda, S3, EC2), enabling seamless scalability and maintaining 99.9% uptime during peak usage by 3K+ users.  
- Created interactive Power BI dashboards to track application funnel metrics, ML model KPIs, and workflow health; shared actionable insights with university leadership.  
- Collaborated with 6+ departments to gather data requirements, standardize reporting formats, and enforce data governance practices for consistent analytics delivery.  

### **Software Engineer â€“ Data Engineering**  
*Cognizant Technology Solutions Ltd. â€“ Chennai, India*  
**Oct 2021 â€“ Dec 2022**  
- Automated SharePoint task flows and data transfers using Power Automate, eliminating repetitive tasks and recovering 20+ hours of weekly effort.  
- Designed and migrated relational schemas for reporting databases; tuned SQL queries to improve performance by 80%, enabling faster insights for business stakeholders.  
- Built a custom Named Entity Recognition (NER) system in spaCy to extract financial terms, improving chatbot intent detection by 25%.  
- Created ETL pipelines to ingest and transform 100K+ financial records/week into cloud-based analytics platforms for fraud detection and user segmentation.  
- Delivered weekly data visualizations and performance reports to product managers and senior stakeholders, translating technical results into business decisions.  

### **Technology Analyst â€“ Data Analytics**  
*Infosys Ltd. â€“ Chennai, India*  
**Dec 2017 â€“ Oct 2021**  
- Managed large-scale content migration from on-premise SharePoint to SharePoint Online across 50+ sites, implementing automated validation to ensure 100% data accuracy and seamless user adoption.  
- Created CI/CD pipelines using Git, Jenkins, Docker, reducing deployment cycles from 2 days to under 1 hour, and ensuring reliable delivery of model updates and visualization layers.  
- Built a Random Forest-based crop yield prediction model, empowering 200+ farmers to optimize agricultural output by 30%.  
- Conducted RFM segmentation and k-means clustering to evaluate customer lifetime value, identifying $300K+ in revenue potential from inactive customer segments.  
- Delivered 15+ real-time Power BI dashboards supporting finance, HR, and supply chain teams, reducing report generation time by 90%.  
- Applied NLP-based classification across 20K+ documents, improving auto-tagging accuracy by 35% and streamlining content discovery.  
- Mentored a team of 10+ junior analysts, conducting hands-on sessions in Python, data visualization, and client-ready storytelling techniques.  
- Regularly conducted UAT (User Acceptance Testing) and system integration testing to verify model outputs, visualization accuracy, and data integrity.  

---

## ğŸš€ Key Projects  
- **Farm Services Platform**: Built an AI-driven platform connecting farmers with agri service providers. Reduced service procurement cost by 40% and increased crop yield by 15%.  
- **Fake News Detection**: Built a sentiment-aware NLP model to detect emotional bias in fake news. Achieved 92% accuracy.  

---

## ğŸ“œ Certifications  
- **AWS Machine Learning â€“ Specialty** *(Expected Feb 2025)*  
- **AWS Cloud Foundations** *(Expected Feb 2025)*  
- **IBM Data Science Professional Certificate** *(Expected Mar 2025)*  
